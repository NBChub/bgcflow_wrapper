{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#bgcflow-wrapper","title":"BGCFlow Wrapper","text":"<p>A snakemake wrapper and utility tools for BGCFlow, a systematic workflow for the analysis of biosynthetic gene clusters across large genomic datasets.</p> <p>For more details, see documentation.</p> <p>Please refer to the <code>BGCFlow</code> WIKI for detailed examples and use cases:</p> <p></p>"},{"location":"#publication","title":"Publication","text":"<p>Matin Nuhamunada, Omkar S Mohite, Patrick V Phaneuf, Bernhard O Palsson, Tilmann Weber, BGCFlow: systematic pangenome workflow for the analysis of biosynthetic gene clusters across large genomic datasets, Nucleic Acids Research, 2024;, gkae314, https://doi.org/10.1093/nar/gkae314</p>"},{"location":"#setup","title":"Setup","text":""},{"location":"#setup-via-conda","title":"Setup via Conda","text":"<p>To install <code>bgcflow_wrapper</code> with conda/mamba, run this command in your terminal:</p> <pre><code># create and activate new conda environment\nmamba create -n bgcflow -c conda-forge python=3.11 pip openjdk -y\nconda activate bgcflow\n\n# install BGCFlow wrapper\npip install bgcflow_wrapper\n</code></pre>"},{"location":"#features","title":"Features","text":""},{"location":"#_1","title":"Home","text":"<pre><code>$ bgcflow\n\nUsage: bgcflow [OPTIONS] COMMAND [ARGS]...\n\n  A snakemake wrapper and utility tools for BGCFlow\n  (https://github.com/NBChub/bgcflow)\n\nOptions:\n  --version   Show the version and exit.\n  -h, --help  Show this message and exit.\n\nCommands:\n  build       Build Markdown report or use dbt to build DuckDB database.\n  clone       Get a clone of BGCFlow to local directory.\n  deploy      [EXPERIMENTAL] Deploy BGCFlow locally using snakedeploy.\n  get-result  View a tree of a project results or get a copy using Rsync.\n  init        Create projects or initiate BGCFlow config from template.\n  pipelines   Get description of available pipelines from BGCFlow.\n  run         A snakemake CLI wrapper to run BGCFlow.\n  serve       Serve static HTML report or other utilities (Metabase, etc.).\n  sync        Upload and sync DuckDB database to Metabase.\n</code></pre>"},{"location":"#credits","title":"Credits","text":"<p>This package was created with the ppw tool. For more information, please visit the project page.</p>"},{"location":"api/","title":"Modules","text":"<p>Top-level package for bgcflow_wrapper.</p>"},{"location":"api/#bgcflow.bgcflow","title":"<code>bgcflow</code>","text":"<p>Main module.</p>"},{"location":"api/#bgcflow.bgcflow.cloner","title":"<code>cloner(**kwargs)</code>","text":"<p>Clone the BGCFlow repository to a specified destination.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Keyword arguments for the cloning.</p> <code>{}</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>bgcflow/bgcflow.py</code> <pre><code>def cloner(**kwargs):\n    \"\"\"\n    Clone the BGCFlow repository to a specified destination.\n\n    Args:\n        **kwargs (dict): Keyword arguments for the cloning.\n\n    Returns:\n        None\n    \"\"\"\n    destination_dir = Path(kwargs[\"destination\"])\n    click.echo(f\"Cloning BGCFlow to {destination_dir}...\")\n    destination_dir.mkdir(parents=True, exist_ok=True)\n    try:\n        Repo.clone_from(\n            \"https://github.com/NBChub/bgcflow.git\",\n            Path(kwargs[\"destination\"]),\n            branch=kwargs[\"branch\"],\n        )\n    except GitCommandError:\n        print(\n            f\"Oops, it seems {kwargs['destination']} already exists and is not an empty directory.\"\n        )\n    return\n</code></pre>"},{"location":"api/#bgcflow.bgcflow.deployer","title":"<code>deployer(**kwargs)</code>","text":"<p>Deploy the BGCFlow repository to a specified destination using Snakedeploy.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Keyword arguments for the deployment.</p> <code>{}</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>bgcflow/bgcflow.py</code> <pre><code>def deployer(**kwargs):\n    \"\"\"\n    Deploy the BGCFlow repository to a specified destination using Snakedeploy.\n\n    Args:\n        **kwargs (dict): Keyword arguments for the deployment.\n\n    Returns:\n        None\n    \"\"\"\n    dplyr(\n        \"https://github.com/NBChub/bgcflow.git\",\n        branch=kwargs[\"branch\"],\n        name=\"bgcflow\",\n        dest_path=Path(kwargs[\"destination\"]),\n        tag=kwargs[\"tag\"],\n    )\n    return\n</code></pre>"},{"location":"api/#bgcflow.bgcflow.get_all_rules","title":"<code>get_all_rules(**kwargs)</code>","text":"<p>Print information about available rules in the BGCFlow repository.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Keyword arguments for the function.</p> <code>{}</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>bgcflow/bgcflow.py</code> <pre><code>def get_all_rules(**kwargs):\n    \"\"\"\n    Print information about available rules in the BGCFlow repository.\n\n    Args:\n        **kwargs (dict): Keyword arguments for the function.\n\n    Returns:\n        None\n    \"\"\"\n    path = Path(kwargs[\"bgcflow_dir\"])\n    rule_file = path / \"workflow/rules.yaml\"\n\n    if rule_file.is_file():\n        with open(rule_file, \"r\") as file:\n            data = yaml.safe_load(file)\n        try:\n            if type(kwargs[\"describe\"]) is str:\n                rule_name = kwargs[\"describe\"]\n                print(f\"Description for {rule_name}:\")\n                print(f\" - {data[rule_name]['description']}\")\n\n            if type(kwargs[\"cite\"]) is str:\n                rule_name = kwargs[\"cite\"]\n                print(f\"Citations for {rule_name}:\")\n                [print(\"-\", c) for c in data[rule_name][\"references\"]]\n\n            if (not type(kwargs[\"describe\"]) is str) and (\n                not type(kwargs[\"cite\"]) is str\n            ):\n                print(\"Printing available rules:\")\n                for item in data.keys():\n                    print(f\" - {item}\")\n\n        except KeyError:\n            rule_name = [\n                r for r in [kwargs[\"describe\"], kwargs[\"cite\"]] if type(r) is str\n            ]\n            print(\n                f\"ERROR: Cannot find rule {rule_name} in dictionary. Find available rules with `bgcflow rules`.\"\n            )\n\n    else:\n        print(\n            \"ERROR: Cannot find BGCFlow directory.\\nPoint to the right directory using `--bgcflow_dir &lt;destination&gt;` or clone BGCFlow using `bgcflow clone &lt;destination&gt;`.\"\n        )\n\n    return\n</code></pre>"},{"location":"api/#bgcflow.bgcflow.snakemake_wrapper","title":"<code>snakemake_wrapper(**kwargs)</code>","text":"<p>Wrapper function for running Snakemake with BGCFlow.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Keyword arguments for Snakemake and BGCFlow.</p> <code>{}</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>bgcflow/bgcflow.py</code> <pre><code>def snakemake_wrapper(**kwargs):\n    \"\"\"\n    Wrapper function for running Snakemake with BGCFlow.\n\n    Args:\n        **kwargs (dict): Keyword arguments for Snakemake and BGCFlow.\n\n    Returns:\n        None\n    \"\"\"\n    p = \"Empty process catcher\"\n\n    dryrun = \"\"\n    touch = \"\"\n    unlock = \"\"\n    until = \"\"\n    profile = \"\"\n    antismash_mode = kwargs[\"antismash_mode\"]\n    os.environ[\"BGCFLOW_ANTISMASH_MODE\"] = antismash_mode\n\n    if kwargs[\"dryrun\"]:\n        dryrun = \"--dryrun\"\n    if kwargs[\"touch\"]:\n        touch = \"--touch\"\n    if kwargs[\"unlock\"]:\n        unlock = \"--unlock\"\n    if kwargs[\"until\"] is not None:\n        until = f\"--until {kwargs['until']}\"\n    if kwargs[\"profile\"] is not None:\n        profile = f\"--profile {kwargs['profile']}\"\n\n    if kwargs[\"monitor_off\"]:\n        pass\n    else:\n        click.echo(\"Monitoring BGCFlow jobs with Panoptes...\")\n        # Run Panoptes if not yet run\n        port = int(kwargs[\"wms_monitor\"].split(\":\")[-1])\n\n        try:\n            item = requests.get(f\"{kwargs['wms_monitor']}/api/service-info\")\n            status = item.json()[\"status\"]\n            assert status == \"running\"\n            click.echo(f\"Panoptes already {status} on {kwargs['wms_monitor']}\")\n        except requests.exceptions.RequestException:  # This is the correct syntax\n            click.echo(\n                f\"Running Panoptes to monitor BGCFlow jobs at {kwargs['wms_monitor']}\"\n            )\n            p = subprocess.Popen(\n                [\"panoptes\", \"--port\", str(port)], stderr=subprocess.DEVNULL\n            )\n            click.echo(f\"Panoptes job id: {p.pid}\")\n\n        # Connect to Panoptes\n        click.echo(\"Connecting to Panoptes...\")\n        ctr = 1\n        for tries in range(10):\n            try:\n                item = requests.get(f\"{kwargs['wms_monitor']}/api/service-info\")\n                status = item.json()[\"status\"]\n                if status == \"running\":\n                    click.echo(f\"Panoptes status: {status}\")\n                    break\n            except requests.exceptions.RequestException:  # This is the correct syntax\n                click.echo(f\"Retrying to connect: {ctr}x\")\n                ctr = ctr + 1\n                time.sleep(1)\n                pass\n            else:\n                time.sleep(1)\n\n    # Check Snakefile\n    valid_workflows = {\n        \"Snakefile\": \"Main BGCFlow snakefile for genome mining\",\n        \"BGC\": \"Subworkflow for comparative analysis of BGCs\",\n        \"Report\": \"Build a static html report of a BGCFlow run\",\n        \"Database\": \"Build a DuckDB database for a BGCFlow run\",\n        \"Metabase\": \"Run a metabase server for visual exploration of the DuckDB database\",\n        \"lsabgc\": \"Run population genetic and evolutionary analysis with lsaBGC-Easy.py using BiG-SCAPE output\",\n        \"ppanggolin\": \"Build pangenome graph and detect region of genome plasticity with PPanGGOLiN\",\n    }\n\n    bgcflow_dir = Path(kwargs[\"bgcflow_dir\"])\n    if kwargs[\"workflow\"] in [\n        \"workflow/Snakefile\",\n        \"workflow/BGC\",\n        \"workflow/Report\",\n        \"workflow/Database\",\n        \"workflow/Metabase\",\n        \"workflow/lsabgc\",\n        \"workflow/ppanggolin\",\n    ]:\n        snakefile = bgcflow_dir / kwargs[\"workflow\"]\n    elif kwargs[\"workflow\"] in [\n        \"Snakefile\",\n        \"BGC\",\n        \"Report\",\n        \"Database\",\n        \"Metabase\",\n        \"lsabgc\",\n        \"ppanggolin\",\n    ]:\n        snakefile = bgcflow_dir / f'workflow/{kwargs[\"workflow\"]}'\n    else:\n        snakefile = bgcflow_dir / kwargs[\"workflow\"]\n\n    assert (\n        snakefile.is_file()\n    ), f\"Snakefile {snakefile} does not exist. Available workflows are:\\n\" + \"\\n\".join(\n        [f\" - {k}: {v}\" for k, v in valid_workflows.items()]\n    )\n\n    # Run Snakemake\n    if kwargs[\"cores\"] &gt; multiprocessing.cpu_count():\n        click.echo(\n            f\"\\nWARNING: Number of cores inputted ({kwargs['cores']}) is higher than the number of available cores ({multiprocessing.cpu_count()}).\"\n        )\n        click.echo(\n            f\"DEBUG: Setting number of cores to available cores: {multiprocessing.cpu_count()}\\n\"\n        )\n        kwargs[\"cores\"] = multiprocessing.cpu_count()\n    else:\n        click.echo(\n            f\"\\nDEBUG: Using {kwargs['cores']} out of {multiprocessing.cpu_count()} available cores\\n\"\n        )\n    snakemake_command = f\"cd {kwargs['bgcflow_dir']} &amp;&amp; snakemake --snakefile {snakefile} --use-conda --keep-going --rerun-incomplete --rerun-triggers mtime -c {kwargs['cores']} {dryrun} {touch} {until} {unlock} {profile} --wms-monitor {kwargs['wms_monitor']}\"\n    click.echo(f\"Running Snakemake with command:\\n{snakemake_command}\")\n    subprocess.call(snakemake_command, shell=True)\n\n    # Kill Panoptes\n    try:\n        if not type(p) == str:\n            click.echo(f\"Stopping panoptes server: PID {p.pid}\")\n            p.kill()\n    except UnboundLocalError as e:\n        click.echo(e)\n    return\n</code></pre>"},{"location":"api/#bgcflow.cli","title":"<code>cli</code>","text":"<p>Console script for bgcflow.</p>"},{"location":"api/#bgcflow.metabase","title":"<code>metabase</code>","text":""},{"location":"api/#bgcflow.metabase.sync_dbt_models_to_metabase","title":"<code>sync_dbt_models_to_metabase(dbt_dir, dbt_database, metabase_host, metabase_database, metabase_user, metabase_password, dbt_schema='main', metabase_http=True, dbt_excludes=None)</code>","text":"<p>Synchronizes dbt models to Metabase using the dbt-metabase package.</p> <p>Parameters:</p> Name Type Description Default <code>dbt_dir</code> <code>str</code> <p>The path to the dbt project directory.</p> required <code>dbt_database</code> <code>str</code> <p>The name of the dbt database to use.</p> required <code>metabase_host</code> <code>str</code> <p>The URL of the Metabase server.</p> required <code>metabase_user</code> <code>str</code> <p>The username of the Metabase account to use.</p> required <code>metabase_password</code> <code>str</code> <p>The password of the Metabase account to use.</p> required <code>metabase_database</code> <code>str</code> <p>The name of the Metabase database to use.</p> required <code>dbt_schema</code> <code>str</code> <p>The name of the dbt schema to use. Defaults to \"main\".</p> <code>'main'</code> <code>metabase_http</code> <code>bool</code> <p>Whether to use HTTP instead of HTTPS for the Metabase connection. Defaults to False.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>The output of the dbt-metabase command as a string.</p> Source code in <code>bgcflow/metabase.py</code> <pre><code>def sync_dbt_models_to_metabase(\n    dbt_dir: str,\n    dbt_database: str,\n    metabase_host: str,\n    metabase_database: str,\n    metabase_user: str,\n    metabase_password: str,\n    dbt_schema: str = \"main\",\n    metabase_http: bool = True,\n    dbt_excludes: list = None,\n) -&gt; str:\n    \"\"\"\n    Synchronizes dbt models to Metabase using the dbt-metabase package.\n\n    Args:\n        dbt_dir (str): The path to the dbt project directory.\n        dbt_database (str): The name of the dbt database to use.\n        metabase_host (str): The URL of the Metabase server.\n        metabase_user (str): The username of the Metabase account to use.\n        metabase_password (str): The password of the Metabase account to use.\n        metabase_database (str): The name of the Metabase database to use.\n        dbt_schema (str, optional): The name of the dbt schema to use. Defaults to \"main\".\n        metabase_http (bool, optional): Whether to use HTTP instead of HTTPS for the Metabase connection. Defaults to False.\n\n    Returns:\n        str: The output of the dbt-metabase command as a string.\n    \"\"\"\n    click.echo(\" - Synchronizing dbt models schema to Metabase...\")\n    if metabase_http:\n        click.echo(\" - Connecting with HTTP method...\")\n        metabase_http = \"--metabase_http\"\n    else:\n        click.echo(\" - Connecting with HTTPS method...\")\n        metabase_http = \"--metabase_https\"\n    command = [\n        \"dbt-metabase\",\n        \"models\",\n        \"--dbt_path\",\n        str(dbt_dir),\n        \"--dbt_database\",\n        dbt_database,\n        \"--metabase_host\",\n        metabase_host.split(\"://\")[-1],\n        \"--metabase_user\",\n        metabase_user,\n        \"--metabase_password\",\n        metabase_password,\n        \"--metabase_database\",\n        metabase_database,\n        \"--dbt_schema\",\n        dbt_schema,\n        metabase_http,\n    ]\n    if dbt_excludes and len(dbt_excludes) &gt; 0:\n        command += [\"--dbt_excludes\", *dbt_excludes]\n\n    # Run the command and capture the output\n    result = subprocess.run(\n        command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True\n    )\n\n    #  the output\n    click.echo(result.stdout)\n    click.echo(result.stderr)\n</code></pre>"},{"location":"api/#bgcflow.metabase.upload_and_sync_to_metabase","title":"<code>upload_and_sync_to_metabase(project_name, bgcflow_dir, dbt_dir, metabase_host, mb_username, mb_password, dbt_schema='main', dbt_database='dbt_bgcflow', metabase_http=True, metabase_database=None, dbt_excludes=None)</code>","text":"<p>Uploads a DuckDB database file generated by dbt to Metabase and syncs the dbt models.</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str</code> <p>The name of the project to upload to Metabase.</p> required <code>bgcflow_dir</code> <code>str</code> <p>The root directory of the BGCFlow project.</p> required <code>dbt_dir</code> <code>str</code> <p>The directory containing the dbt project to upload. If None, the directory is inferred from the BGCFlow project directory.</p> required <code>metabase_host</code> <code>str</code> <p>The URL of the Metabase server.</p> required <code>mb_username</code> <code>str</code> <p>The Metabase username. If None, the user will be prompted to enter their username.</p> required <code>mb_password</code> <code>str</code> <p>The Metabase password. If None, the user will be prompted to enter their password.</p> required <code>dbt_schema</code> <code>str</code> <p>The name of the dbt schema to use.</p> <code>'main'</code> <code>dbt_database</code> <code>str</code> <p>The name of the dbt database to use.</p> <code>'dbt_bgcflow'</code> <code>metabase_http</code> <code>bool</code> <p>Whether to use HTTP instead of HTTPS to connect to Metabase.</p> <code>True</code> <code>metabase_database</code> <code>str</code> <p>The name of the Metabase database to use. If None, the project name is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The output of the dbt-metabase command as a string.</p> <p>Exceptions:</p> Type Description <code>AssertionError</code> <p>If the dbt_dir or bgcflow_dir do not exist or are not directories.</p> <code>subprocess.CalledProcessError</code> <p>If the dbt-metabase command fails.</p> Source code in <code>bgcflow/metabase.py</code> <pre><code>def upload_and_sync_to_metabase(\n    project_name: str,\n    bgcflow_dir: str,\n    dbt_dir: str,\n    metabase_host: str,\n    mb_username: str,\n    mb_password: str,\n    dbt_schema: str = \"main\",\n    dbt_database: str = \"dbt_bgcflow\",\n    metabase_http: bool = True,\n    metabase_database: str = None,\n    dbt_excludes: list = None,\n) -&gt; str:\n    \"\"\"\n    Uploads a DuckDB database file generated by dbt to Metabase and syncs the dbt models.\n\n    Args:\n        project_name (str): The name of the project to upload to Metabase.\n        bgcflow_dir (str): The root directory of the BGCFlow project.\n        dbt_dir (str): The directory containing the dbt project to upload. If None, the directory is inferred from the BGCFlow project directory.\n        metabase_host (str): The URL of the Metabase server.\n        mb_username (str): The Metabase username. If None, the user will be prompted to enter their username.\n        mb_password (str): The Metabase password. If None, the user will be prompted to enter their password.\n        dbt_schema (str): The name of the dbt schema to use.\n        dbt_database (str): The name of the dbt database to use.\n        metabase_http (bool): Whether to use HTTP instead of HTTPS to connect to Metabase.\n        metabase_database (str): The name of the Metabase database to use. If None, the project name is used.\n\n    Returns:\n        str: The output of the dbt-metabase command as a string.\n\n    Raises:\n        AssertionError: If the dbt_dir or bgcflow_dir do not exist or are not directories.\n        subprocess.CalledProcessError: If the dbt-metabase command fails.\n    \"\"\"\n    # available dbt models in bgcflow_dbt-duckdb v0.2.1\n    dbt_model_dict = {\n        \"query-bigslice\": [\"bigfam_hits\", \"bigfam_network\"],\n        \"bigscape\": [\"bigscape_cluster\", \"bigscape_network\", \"mibig_hits\"],\n        \"checkm\": [\"checkm\"],\n        \"seqfu\": [\"seqfu\"],\n        \"antismash\": [\"genomes\"],\n    }\n\n    if dbt_excludes is None:\n        dbt_excludes = []\n    else:\n        dbt_excludes = list(dbt_excludes)\n\n    if dbt_dir is None:\n        report_dir = Path(bgcflow_dir) / f\"data/processed/{project_name}\"\n        click.echo(f\" - Accessing BGCFlow report directory in: {report_dir}\")\n        with open(report_dir / \"metadata/dependency_versions.json\", \"r\") as f:\n            dependency_version = json.load(f)\n        antismash_version = dependency_version[\"antismash\"]\n        click.echo(f\" - AntiSMASH version: {antismash_version}\")\n\n        project_metadata_json = report_dir / \"metadata/project_metadata.json\"\n        click.echo(f\" - Reading project metadata from: {project_metadata_json}\")\n        with open(project_metadata_json, \"r\") as f:\n            project_metadata = json.load(f)\n        used_pipelines = list(project_metadata[project_name][\"rule_used\"].keys())\n        click.echo(f\" - Used pipelines: {', '.join(used_pipelines)}\")\n        for pipeline in dbt_model_dict.keys():\n            if pipeline not in used_pipelines:\n                dbt_excludes += dbt_model_dict[pipeline]\n        click.echo(f\" - Excluding models for sync: {', '.join(dbt_excludes)}\")\n        dbt_dir = report_dir / f\"dbt/antiSMASH_{antismash_version}\"\n\n    elif isinstance(dbt_dir, str):\n        click.echo(f\" - Accessing dbt project directory in: {dbt_dir}\")\n        click.echo(\n            f\" - Using all models for sync: {', '.join(list(dbt_model_dict.values()))}\"\n        )\n        dbt_dir = Path(dbt_dir)\n\n    # Get Metabase session token\n    if mb_username is None:\n        mb_username = click.prompt(\"Enter your Metabase username\")\n    if mb_password is None:\n        mb_password = click.prompt(\"Enter your Metabase password\", hide_input=True)\n\n    response, session_token = upload_dbt_to_metabase(\n        project_name, bgcflow_dir, dbt_dir, metabase_host, mb_username, mb_password\n    )\n    if response == 200:\n        if metabase_database is None:\n            metabase_database = project_name\n        sync_dbt_models_to_metabase(\n            dbt_dir,\n            dbt_database,\n            metabase_host,\n            metabase_database,\n            mb_username,\n            mb_password,\n            dbt_schema,\n            metabase_http,\n            dbt_excludes,\n        )\n</code></pre>"},{"location":"api/#bgcflow.metabase.upload_dbt_to_metabase","title":"<code>upload_dbt_to_metabase(project_name, bgcflow_dir, dbt_dir, metabase_host, mb_username, mb_password)</code>","text":"<p>Uploads a DuckDB database file generated by dbt to Metabase.</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str</code> <p>The name of the project to upload to Metabase.</p> required <code>bgcflow_dir</code> <code>str</code> <p>The path to the BGCflow directory.</p> required <code>dbt_dir</code> <code>str</code> <p>The path to the dbt directory containing the DuckDB database file.</p> required <code>metabase_host</code> <code>str</code> <p>The URL of the Metabase server.</p> required <code>mb_username</code> <code>str</code> <p>The username to use for authentication with Metabase.</p> required <code>mb_password</code> <code>str</code> <p>The password to use for authentication with Metabase.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The HTTP status code of the request.</p> <p>Exceptions:</p> Type Description <code>AssertionError</code> <p>If the DuckDB database file does not exist or is not a regular file.</p> Source code in <code>bgcflow/metabase.py</code> <pre><code>def upload_dbt_to_metabase(\n    project_name: str,\n    bgcflow_dir: str,\n    dbt_dir: str,\n    metabase_host: str,\n    mb_username: str,\n    mb_password: str,\n) -&gt; str:\n    \"\"\"\n    Uploads a DuckDB database file generated by dbt to Metabase.\n\n    Args:\n        project_name (str): The name of the project to upload to Metabase.\n        bgcflow_dir (str): The path to the BGCflow directory.\n        dbt_dir (str): The path to the dbt directory containing the DuckDB database file.\n        metabase_host (str): The URL of the Metabase server.\n        mb_username (str): The username to use for authentication with Metabase.\n        mb_password (str): The password to use for authentication with Metabase.\n\n    Returns:\n        str: The HTTP status code of the request.\n\n    Raises:\n        AssertionError: If the DuckDB database file does not exist or is not a regular file.\n\n    \"\"\"\n    duckdb_path = dbt_dir / \"dbt_bgcflow.duckdb\"\n    assert (\n        duckdb_path.is_file()\n    ), f\"Error: {duckdb_path} does not exist or is not a regular file\"\n\n    session_response = requests.post(\n        f\"{metabase_host}/api/session\",\n        json={\"username\": mb_username, \"password\": mb_password},\n    )\n    session_token = session_response.json()[\"id\"]\n\n    # Check if database already exists\n    database_response = requests.get(\n        f\"{metabase_host}/api/database\", headers={\"X-Metabase-Session\": session_token}\n    )\n    databases = database_response.json()\n    database_id = None\n    for k, v in databases.items():\n        if k == \"data\":\n            for db in v:\n                if db[\"name\"] == project_name:\n                    database_id = db[\"id\"]\n                    break\n\n    # Prompt user to continue or cancel upload\n    if database_id is not None:\n        user_input = input(\n            f\" - WARNING: A database with the name '{project_name}' already exists in Metabase. Do you want to continue with the upload? (y/n) \"\n        )\n        if user_input.lower() != \"y\":\n            click.echo(\" - Database upload cancelled by user\")\n            return\n\n    # Upload or update database in Metabase\n    if database_id is None:\n        database_response = requests.post(\n            f\"{metabase_host}/api/database\",\n            headers={\"X-Metabase-Session\": session_token},\n            json={\n                \"engine\": \"duckdb\",\n                \"name\": project_name,\n                \"details\": {\"database_file\": str(duckdb_path.resolve())},\n            },\n        )\n        if database_response.status_code == 200:\n            click.echo(f\" - Database '{project_name}' uploaded successfully\")\n        else:\n            click.echo(\n                f\" - Error uploading database '{project_name}': {database_response.text}\"\n            )\n\n    else:\n        database_response = requests.put(\n            f\"{metabase_host}/api/database/{database_id}\",\n            headers={\"X-Metabase-Session\": session_token},\n            json={\n                \"engine\": \"duckdb\",\n                \"name\": project_name,\n                \"details\": {\"database_file\": str(duckdb_path.resolve())},\n            },\n        )\n        if database_response.status_code == 200:\n            click.echo(f\" - Database '{project_name}' updated successfully\")\n        else:\n            click.echo(\n                f\" - Error updating database '{project_name}': {database_response.text}\"\n            )\n\n    return database_response.status_code, session_token\n</code></pre>"},{"location":"api/#bgcflow.mkdocs","title":"<code>mkdocs</code>","text":""},{"location":"api/#bgcflow.mkdocs.Dict2Class","title":"<code> Dict2Class        </code>","text":"<p>A class that converts a dictionary to an object with attributes.</p> <p>Parameters:</p> Name Type Description Default <code>my_dict</code> <code>dict</code> <p>The dictionary to convert to an object.</p> required <p>Methods</p> <p>print_references():     Returns a formatted string of the <code>references</code> attribute of the object.</p> Source code in <code>bgcflow/mkdocs.py</code> <pre><code>class Dict2Class(object):\n    \"\"\"\n    A class that converts a dictionary to an object with attributes.\n\n    Args:\n        my_dict (dict): The dictionary to convert to an object.\n\n    Attributes:\n        All keys in the dictionary are converted to attributes of the object.\n\n    Methods:\n        print_references():\n            Returns a formatted string of the `references` attribute of the object.\n    \"\"\"\n\n    def __init__(self, my_dict):\n        \"\"\"\n        Initializes the object with attributes from the dictionary.\n\n        Args:\n            my_dict (dict): The dictionary to convert to an object.\n        \"\"\"\n        for key in my_dict:\n            setattr(self, key, my_dict[key])\n\n    def print_references(self):\n        \"\"\"\n        Returns a formatted string of the `references` attribute of the object.\n\n        Returns:\n            str: A formatted string of the `references` attribute of the object.\n        \"\"\"\n        text = \"\"\n        for r in self.references:\n            text = \"\\n\".join([text, f\"- {r}\"])\n        return text\n</code></pre>"},{"location":"api/#bgcflow.mkdocs.Dict2Class.__init__","title":"<code>__init__(self, my_dict)</code>  <code>special</code>","text":"<p>Initializes the object with attributes from the dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>my_dict</code> <code>dict</code> <p>The dictionary to convert to an object.</p> required Source code in <code>bgcflow/mkdocs.py</code> <pre><code>def __init__(self, my_dict):\n    \"\"\"\n    Initializes the object with attributes from the dictionary.\n\n    Args:\n        my_dict (dict): The dictionary to convert to an object.\n    \"\"\"\n    for key in my_dict:\n        setattr(self, key, my_dict[key])\n</code></pre>"},{"location":"api/#bgcflow.mkdocs.Dict2Class.print_references","title":"<code>print_references(self)</code>","text":"<p>Returns a formatted string of the <code>references</code> attribute of the object.</p> <p>Returns:</p> Type Description <code>str</code> <p>A formatted string of the <code>references</code> attribute of the object.</p> Source code in <code>bgcflow/mkdocs.py</code> <pre><code>def print_references(self):\n    \"\"\"\n    Returns a formatted string of the `references` attribute of the object.\n\n    Returns:\n        str: A formatted string of the `references` attribute of the object.\n    \"\"\"\n    text = \"\"\n    for r in self.references:\n        text = \"\\n\".join([text, f\"- {r}\"])\n    return text\n</code></pre>"},{"location":"api/#bgcflow.mkdocs.generate_mkdocs_report","title":"<code>generate_mkdocs_report(bgcflow_dir, project_name, port=8001, fileserver='http://localhost:8002', ipynb=True)</code>","text":"<p>Generates an MkDocs report for a BGCFlow project.</p> <p>Parameters:</p> Name Type Description Default <code>bgcflow_dir</code> <code>str</code> <p>The path to the BGCFlow project directory.</p> required <code>project_name</code> <code>str</code> <p>The name of the BGCFlow project.</p> required <code>port</code> <code>int</code> <p>The port number to use for the MkDocs server, by default 8001.</p> <code>8001</code> <code>fileserver</code> <code>str</code> <p>The URL of the file server to use, by default \"http://localhost:8002\".</p> <code>'http://localhost:8002'</code> <code>ipynb</code> <code>bool</code> <p>Whether to use IPython notebooks for the reports, by default True.</p> <code>True</code> Source code in <code>bgcflow/mkdocs.py</code> <pre><code>def generate_mkdocs_report(\n    bgcflow_dir: str,\n    project_name: str,\n    port: int = 8001,\n    fileserver: str = \"http://localhost:8002\",\n    ipynb: bool = True,\n) -&gt; None:\n    \"\"\"\n    Generates an MkDocs report for a BGCFlow project.\n\n    Args:\n        bgcflow_dir (str): The path to the BGCFlow project directory.\n        project_name (str: The name of the BGCFlow project.\n        port (int, optional): The port number to use for the MkDocs server, by default 8001.\n        fileserver (str, optional): The URL of the file server to use, by default \"http://localhost:8002\".\n        ipynb (bool, optional): Whether to use IPython notebooks for the reports, by default True.\n    \"\"\"\n    logging.info(\"Checking input folder..\")\n\n    # is it a bgcflow data directory or just a result directory?\n    input_dir = Path(bgcflow_dir)\n    if (input_dir / \"metadata/project_metadata.json\").is_file():\n        report_dir = input_dir\n    else:\n        report_dir = input_dir / f\"data/processed/{project_name}\"\n        assert (\n            report_dir / \"metadata/project_metadata.json\"\n        ).is_file(), \"Unable to find BGCFlow results\"\n    logging.debug(f\"Found project_metadata. Using [{report_dir}] as report directory.\")\n\n    # Get project metadata\n    p = load_project_metadata(report_dir / \"metadata/project_metadata.json\")\n    assert (\n        p.name == project_name\n    ), \"Project metadata does not match with user provided input!\"\n    logging.debug(\n        f\"Project [{p.name}] was analysed using BGCFlow version {p.bgcflow_version}\"\n    )\n\n    # available reports, check all output files\n    logging.debug(f\"Available reports: {list(p.rule_used.keys())}\")\n    df_results = pd.DataFrame.from_dict(p.rule_used).T\n\n    # check available reports\n    logging.info(\"Preparing mkdocs config...\")\n    if ipynb:\n        extension = \"ipynb\"\n    else:\n        extension = \"md\"\n\n    report_category_containers = {}\n    for r, v in p.rule_used.items():\n        jupyter_template = report_dir / f\"docs/{r}.{extension}\"\n        # logging.debug(jupyter_template.is_file()) # TO DO ASSERT IPYNB FILES, THEY SHOULD BE IN THE DOCS\n        logging.debug(f\"Adding report [{r} : {jupyter_template.name}]\")\n        report_category = v[\"category\"]\n        if report_category not in report_category_containers.keys():\n            report_category_containers[report_category] = []\n        report_category_containers[report_category].append({r: jupyter_template.name})\n\n    for k, v in report_category_containers.items():\n        mkdocs_template[\"nav\"].append({k: v})\n\n    # write mkdocs template\n    mkdocs_yml = report_dir / \"mkdocs.yml\"\n    logging.info(f\"Generating mkdocs config at: {mkdocs_yml}\")\n    write_mkdocs_file(mkdocs_template, mkdocs_yml, \"yaml\")\n\n    # Generate index.md\n    docs_dir = report_dir / \"docs\"\n    docs_dir.mkdir(exist_ok=True, parents=True)\n    mkdocs_index = docs_dir / \"index.md\"\n    logging.info(f\"Generating homepage at: {mkdocs_index}\")\n    df_results.loc[:, \"BGCFlow_rules\"] = df_results.index\n    df_results = df_results.loc[:, [\"BGCFlow_rules\", \"description\"]].reset_index(\n        drop=True\n    )\n    df_results.loc[:, \"BGCFlow_rules\"] = [\n        f\"[{i}]({i}/)\" + \"{.md-button}\" for i in df_results.loc[:, \"BGCFlow_rules\"]\n    ]\n    data = {\n        \"p_name\": p.name,\n        \"p_description\": p.description,\n        \"p_sample_size\": p.sample_size,\n        \"p_references\": p.references,\n        \"rule_table\": df_results.to_markdown(index=False),\n    }\n    j2_template = Template(index_template)\n\n    write_mkdocs_file(j2_template.render(data), mkdocs_index, \"write\")\n\n    # generate main.py macros\n    mkdocs_py = report_dir / \"main.py\"\n    logging.info(f\"Generating python macros at: {mkdocs_py}\")\n    j2_template = Template(macros_template)\n    write_mkdocs_file(\n        j2_template.render({\"file_server\": fileserver}), mkdocs_py, \"write\"\n    )\n\n    # generate custom javascripts\n    # script_dir = docs_dir / \"scripts\"\n    # script_dir.mkdir(parents=True, exist_ok=True)\n    # logging.info(f\"Generating custom site javascripts at: {script_dir / 'site.js'}\")\n    # with open(script_dir / 'site.js', \"w\") as f:\n    #    f.write(script_js)\n\n    # extend main html\n    override_dir = report_dir / \"overrides\"\n    override_dir.mkdir(exist_ok=True, parents=True)\n    logging.info(f\"Extends main html: {override_dir / 'main.html'}\")\n    with open(override_dir / \"main.html\", \"w\") as f:\n        f.write(main_html)\n\n    # generate assets\n    asset_path = docs_dir / \"assets/bgcflow\"\n    asset_path.mkdir(exist_ok=True, parents=True)\n    logging.info(\"Generating assets...\")\n    logo_path = asset_path / \"BGCFlow_logo.svg\"\n    shutil.copy(Path(__file__).parent / \"outputs/svg/BGCFlow_logo.svg\", logo_path)\n\n    # generate symlink\n    # for r in ['antismash', 'bigscape']:\n    #    target_path_raw = report_dir / r\n    #    for target_path in target_path_raw.glob(\"*\"):\n    #        if any(target_path.name.startswith(keywords) for keywords in ['result', '6']):\n    #            if target_path.is_dir():\n    #                symlink_path = asset_path / r\n    #                if symlink_path.is_symlink():\n    #                    symlink_path.unlink()\n    #                symlink_path.symlink_to(target_path.resolve())\n\n    # Running fileserver\n    if fileserver == \"http://localhost:8002\":\n        fs = subprocess.Popen(\n            [\n                \"python\",\n                \"-m\",\n                \"http.server\",\n                \"--directory\",\n                report_dir,\n                fileserver.split(\":\")[-1],\n            ],\n            stderr=subprocess.DEVNULL,\n        )\n        fs_run_by_bgcflow = True\n        logging.info(f\"Running http file-server. Job id: {fs.pid}\")\n    else:\n        fs_run_by_bgcflow = False\n    # dumping file server location\n    with open(\"bgcflow_wrapper.log\", \"w\") as f:\n        log_port = {\"report_server\": port, \"file_server\": fileserver}\n        if fs_run_by_bgcflow:\n            log_port[\"pid\"] = fs.pid\n        json.dump(log_port, f, indent=2)\n\n    try:\n        signal.signal(signal.SIGINT, signal_handler)\n        subprocess.call(\n            f\"(cd {str(report_dir)} &amp;&amp; mkdocs serve -a localhost:{port})\", shell=True\n        )\n        if fs_run_by_bgcflow:\n            fs.kill()\n        # asset_path.rmdir()\n    except subprocess.CalledProcessError:\n        if fs_run_by_bgcflow:\n            fs.kill()\n        # asset_path.rmdir()\n    return\n</code></pre>"},{"location":"api/#bgcflow.mkdocs.load_project_metadata","title":"<code>load_project_metadata(path_to_metadata)</code>","text":"<p>Loads project metadata from a JSON file and returns it as an object.</p> <p>Parameters:</p> Name Type Description Default <code>path_to_metadata</code> <code>str or Path</code> <p>The path to the JSON file containing the project metadata.</p> required <p>Returns:</p> Type Description <code>Dict2Class</code> <p>An object representing the project metadata.</p> Source code in <code>bgcflow/mkdocs.py</code> <pre><code>def load_project_metadata(path_to_metadata):\n    \"\"\"\n    Loads project metadata from a JSON file and returns it as an object.\n\n    Args:\n        path_to_metadata (str or Path): The path to the JSON file containing the project metadata.\n\n    Returns:\n        Dict2Class: An object representing the project metadata.\n    \"\"\"\n    with open(path_to_metadata, \"r\") as f:\n        project_metadata = json.load(f)\n        p = list(project_metadata.values())[0]\n        p[\"name\"] = [i for i in project_metadata.keys()][0]\n        p = Dict2Class(p)\n    return p\n</code></pre>"},{"location":"api/#bgcflow.mkdocs.signal_handler","title":"<code>signal_handler(signal, frame)</code>","text":"<p>A signal handler function that prints a message and exits the program.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>int</code> <p>The signal number.</p> required <code>frame</code> <code>FrameType</code> <p>The current stack frame.</p> required Source code in <code>bgcflow/mkdocs.py</code> <pre><code>def signal_handler(signal, frame):\n    \"\"\"\n    A signal handler function that prints a message and exits the program.\n\n    Args:\n        signal (int): The signal number.\n        frame (FrameType): The current stack frame.\n    \"\"\"\n    print(\"\\nThank you for using BGCFlow Report!\")\n    # with open('bgcflow_wrapper.log', \"r\") as f:\n    #    log_port = json.load(f)\n    #    os.kill(log_port['pid'], signal.signal.SIGKILL)\n    sys.exit(0)\n</code></pre>"},{"location":"api/#bgcflow.mkdocs.write_mkdocs_file","title":"<code>write_mkdocs_file(data_input, output_file, action)</code>","text":"<p>Writes data to a file in either YAML or plain text format.</p> <p>Parameters:</p> Name Type Description Default <code>data_input</code> <code>dict or str</code> <p>The data to write to the file.</p> required <code>output_file</code> <code>str or Path</code> <p>The path to the file to write.</p> required <code>action</code> <code>str</code> <p>The action to perform. Either \"yaml\" to write the data in YAML format, or \"write\" to write the data as plain text.</p> required Source code in <code>bgcflow/mkdocs.py</code> <pre><code>def write_mkdocs_file(data_input, output_file, action):\n    \"\"\"\n    Writes data to a file in either YAML or plain text format.\n\n    Args:\n        data_input (dict or str): The data to write to the file.\n        output_file (str or Path): The path to the file to write.\n        action (str): The action to perform. Either \"yaml\" to write the data in YAML format, or \"write\" to write the data as plain text.\n    \"\"\"\n    if output_file.exists():\n        overwrite = input(\n            f\"WARNING: {output_file} already exists. Do you want to overwrite it? (y/n) \"\n        )\n        if overwrite.lower() != \"y\":\n            print(\"Skipping file write.\")\n        else:\n            # continue with writing the file\n            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n                if action == \"yaml\":\n                    yaml.dump(data_input, f)\n                elif action == \"write\":\n                    f.write(data_input)\n    else:\n        # continue with writing the file\n        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n            if action == \"yaml\":\n                yaml.dump(data_input, f)\n            elif action == \"write\":\n                f.write(data_input)\n</code></pre>"},{"location":"api/#bgcflow.projects_util","title":"<code>projects_util</code>","text":""},{"location":"api/#bgcflow.projects_util.bgcflow_init","title":"<code>bgcflow_init(bgcflow_dir, global_config)</code>","text":"<p>Initialize BGCFlow configuration and display available projects.</p> <p>Initializes BGCFlow configuration based on the provided directory and global configuration path. If the global configuration file exists, it lists the available projects. If not, generates a global configuration file from the template and provides instructions for a test run.</p> <p>Parameters:</p> Name Type Description Default <code>bgcflow_dir</code> <code>str or pathlib.PosixPath</code> <p>The directory where the BGCFlow configuration is located.</p> required <code>global_config</code> <code>str or pathlib.PosixPath</code> <p>The path to the global configuration file.</p> required Source code in <code>bgcflow/projects_util.py</code> <pre><code>def bgcflow_init(bgcflow_dir, global_config):\n    \"\"\"\n    Initialize BGCFlow configuration and display available projects.\n\n    Initializes BGCFlow configuration based on the provided directory and global configuration path.\n    If the global configuration file exists, it lists the available projects.\n    If not, generates a global configuration file from the template and provides instructions for a test run.\n\n    Args:\n        bgcflow_dir (str or pathlib.PosixPath): The directory where the BGCFlow configuration is located.\n        global_config (str or pathlib.PosixPath): The path to the global configuration file.\n    \"\"\"\n    # check if global config available\n    if global_config.is_file():\n        # grab available projects\n        logging.debug(f\"Found config file at: {global_config}\")\n        with open(global_config, \"r\") as file:\n            config_yaml = yaml.safe_load(file)\n            project_names = [p for p in config_yaml[\"projects\"]]\n            list_of_projects = {}\n            for p in project_names:\n                if \"pep\" in p.keys():\n                    p[\"name\"] = p.pop(\"pep\")\n                if p[\"name\"].endswith(\".yaml\"):\n                    pep = peppy.Project(\n                        str(bgcflow_dir / p[\"name\"]), sample_table_index=\"genome_id\"\n                    )\n                    name = pep.name\n                    file_path = pep.config[\"sample_table\"]\n                else:\n                    name = p[\"name\"]\n                    file_path = p[\"samples\"]\n                list_of_projects[name] = file_path\n\n            print(\"Available projects:\")\n            for p in list_of_projects.keys():\n                print(f\" - {p} : {file_path}\")\n    else:\n        generate_global_config(bgcflow_dir, global_config)\n\n    print(\"\\nDo a test run by: `bgcflow run -n`\")\n</code></pre>"},{"location":"api/#bgcflow.projects_util.copy_final_output","title":"<code>copy_final_output(**kwargs)</code>","text":"<p>Copy final project output files to a specified destination.</p> <p>This function facilitates the copying of processed project output files to a designated destination. It can also preserve symbolic links during the copy process if specified.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Keyword argument for the function.</p> <code>{}</code> <p>Keyword arguments:</p> Name Type Description <code>bgcflow_dir</code> <code>str</code> <p>The directory where the BGCFlow configuration is located.</p> <code>project</code> <code>str</code> <p>The name of the project whose output should be copied.</p> <code>resolve_symlinks</code> <code>str</code> <p>Indicate whether to preserve symbolic links. Defaults to False.</p> <code>destination</code> <code>str</code> <p>The destination directory where the output should be copied.</p> Source code in <code>bgcflow/projects_util.py</code> <pre><code>def copy_final_output(**kwargs):\n    \"\"\"\n    Copy final project output files to a specified destination.\n\n    This function facilitates the copying of processed project output files to a designated destination. It can\n    also preserve symbolic links during the copy process if specified.\n\n    Args:\n        **kwargs (dict): Keyword argument for the function.\n\n    Keyword arguments:\n        bgcflow_dir (str): The directory where the BGCFlow configuration is located.\n        project (str): The name of the project whose output should be copied.\n        resolve_symlinks (str, optional): Indicate whether to preserve symbolic links. Defaults to False.\n        destination (str): The destination directory where the output should be copied.\n    \"\"\"\n    bgcflow_dir = Path(kwargs[\"bgcflow_dir\"]).resolve()\n    project_output = bgcflow_dir / f\"data/processed/{kwargs['project']}\"\n    assert (\n        project_output.is_dir()\n    ), f\"ERROR: Cannot find project [{kwargs['project']}] results. Run `bgcflow init` to find available projects.\"\n    if \"resolve_symlinks\" in kwargs.keys():\n        assert kwargs[\"resolve_symlinks\"] in [\n            \"True\",\n            \"False\",\n        ], f'Invalid argument {kwargs[\"resolve_symlinks\"]} in --resolve-symlinks. Choose between \"True\" or \"False\"'\n        if kwargs[\"resolve_symlinks\"] == \"True\":\n            resolve_symlinks = \"-L\"\n    else:\n        resolve_symlinks = \"\"\n    exclude_copy = f\"{str(project_output.stem)}/bigscape/*/cache\"\n    command = [\n        \"rsync\",\n        \"-avPhr\",\n        resolve_symlinks,\n        \"--exclude\",\n        exclude_copy,\n        str(project_output),\n        kwargs[\"destination\"],\n    ]\n    logging.debug(f'Running command: {\" \".join(command)}')\n    subprocess.call(command)\n</code></pre>"},{"location":"api/#bgcflow.projects_util.generate_global_config","title":"<code>generate_global_config(bgcflow_dir, global_config)</code>","text":"<p>Generate a BGCFlow global configuration file from a template.</p> <p>Copies the template configuration file to the specified global configuration path.</p> <p>Parameters:</p> Name Type Description Default <code>bgcflow_dir</code> <code>str or pathlib.PosixPath</code> <p>The directory where the BGCFlow configuration is located.</p> required <code>global_config</code> <code>str or pathlib.PosixPath</code> <p>The path to the global configuration file to be generated.</p> required Source code in <code>bgcflow/projects_util.py</code> <pre><code>def generate_global_config(bgcflow_dir, global_config):\n    \"\"\"\n    Generate a BGCFlow global configuration file from a template.\n\n    Copies the template configuration file to the specified global configuration path.\n\n    Args:\n        bgcflow_dir (str or pathlib.PosixPath): The directory where the BGCFlow configuration is located.\n        global_config (str or pathlib.PosixPath): The path to the global configuration file to be generated.\n    \"\"\"\n    logging.info(f\"Generating config file from template at: {global_config}\")\n    template_config = bgcflow_dir / \".examples/_config_example.yaml\"\n    assert (\n        template_config.is_file()\n    ), \"Cannot find template file. Are you using BGCFlow version &gt;= 0.4.1?\"\n\n    shutil.copy(template_config, global_config)\n\n    # scan for example projects\n    def copy_project_example(project_type):\n        \"\"\"\n        Scan global config for example projects and (sub projects) and copy them to the config directory.\n        \"\"\"\n        with open(global_config, \"r\") as file:\n            config_yaml = yaml.safe_load(file)\n        example_projects = [\n            Path(p[\"pep\"])\n            for p in config_yaml[project_type]\n            if \"pep\" in p.keys() and p[\"pep\"].endswith(\".yaml\")\n        ]\n\n        for example_project in example_projects:\n            example_project_dir = (\n                bgcflow_dir / \".examples\" / example_project.parent.name\n            )\n            target_dir = bgcflow_dir / \"config\" / example_project_dir.name\n            if str(example_project).startswith(\".examples\"):\n                logging.warning(\n                    f\"\\n - WARNING: You are using BGCFlow version &lt;= 0.7.1. In the global config file (`{global_config}`), please change the location of your `{example_project}` to `config/{example_project.parent.name}/{example_project.name}`.\"\n                )\n            shutil.copytree(example_project_dir, target_dir)\n\n    for project_type in [\"projects\", \"bgc_projects\"]:\n        copy_project_example(project_type)\n</code></pre>"},{"location":"api/#bgcflow.projects_util.generate_project","title":"<code>generate_project(bgcflow_dir, project_name, pep_version='2.1.0', use_project_rules=False, samples_csv=False, prokka_db=False, gtdb_tax=False, description=False)</code>","text":"<p>Generate a PEP project configuration in BGCFlow.</p> <p>This function creates a configuration file for a Project Enhanced Pipelines (PEP) project within the BGCFlow framework. It allows you to define various aspects of the project, such as its name, version, description, sample data, custom annotations, and more.</p> <p>Parameters:</p> Name Type Description Default <code>bgcflow_dir</code> <code>str or pathlib.PosixPath</code> <p>The directory where the BGCFlow configuration is located.</p> required <code>project_name</code> <code>str</code> <p>The name of the project.</p> required <code>pep_version</code> <code>str</code> <p>The version of the PEP specification. Defaults to \"2.1.0\".</p> <code>'2.1.0'</code> <code>use_project_rules</code> <code>bool</code> <p>Flag indicating whether to use project-specific rules. Defaults to False.</p> <code>False</code> <code>samples_csv</code> <code>pd.core.frame.DataFrame or str</code> <p>Sample data in Pandas DataFrame or path to a CSV file. Defaults to False.</p> <code>False</code> <code>prokka_db</code> <code>str</code> <p>Path to a custom Prokka annotation file. Defaults to False.</p> <code>False</code> <code>gtdb_tax</code> <code>str</code> <p>Path to a custom GTDB taxonomy file. Defaults to False.</p> <code>False</code> <code>description</code> <code>str</code> <p>Description for the project. Defaults to False.</p> <code>False</code> Source code in <code>bgcflow/projects_util.py</code> <pre><code>def generate_project(\n    bgcflow_dir,\n    project_name,\n    pep_version=\"2.1.0\",\n    use_project_rules=False,\n    samples_csv=False,\n    prokka_db=False,\n    gtdb_tax=False,\n    description=False,\n):\n    \"\"\"\n    Generate a PEP project configuration in BGCFlow.\n\n    This function creates a configuration file for a Project Enhanced Pipelines (PEP)\n    project within the BGCFlow framework. It allows you to define various aspects of\n    the project, such as its name, version, description, sample data, custom annotations,\n    and more.\n\n    Args:\n        bgcflow_dir (str or pathlib.PosixPath): The directory where the BGCFlow configuration is located.\n        project_name (str): The name of the project.\n        pep_version (str, optional): The version of the PEP specification. Defaults to \"2.1.0\".\n        use_project_rules (bool, optional): Flag indicating whether to use project-specific rules. Defaults to False.\n        samples_csv (pd.core.frame.DataFrame or str, optional): Sample data in Pandas DataFrame or path to a CSV file. Defaults to False.\n        prokka_db (str, optional): Path to a custom Prokka annotation file. Defaults to False.\n        gtdb_tax (str, optional): Path to a custom GTDB taxonomy file. Defaults to False.\n        description (str, optional): Description for the project. Defaults to False.\n    \"\"\"\n\n    # Ensure bgcflow_dir is a pathlib.PosixPath\n    if not isinstance(bgcflow_dir, Path):\n        bgcflow_dir = Path(bgcflow_dir)\n\n    # Define paths and template dictionary\n    global_config = bgcflow_dir / \"config/config.yaml\"\n    template_dict = {\n        \"name\": project_name,\n        \"pep_version\": pep_version,\n        \"description\": \"&lt;TO DO: give a description to your project&gt;\",\n        \"sample_table\": \"samples.csv\",\n        \"prokka-db\": \"OPTIONAL: relative path to your `prokka-db.csv`\",\n        \"gtdb-tax\": \"OPTIONAL: relative path to your `gtdbtk.bac120.summary.tsv`\",\n    }\n\n    # Update template_dict with project rules if enabled\n    if use_project_rules:\n        with open(bgcflow_dir / \"workflow/rules.yaml\", \"r\") as file:\n            available_rules = yaml.safe_load(file)\n            available_rules = {rule: \"FALSE\" for rule in available_rules.keys()}\n            template_dict[\"rules\"] = available_rules\n\n    # Create project directory\n    project_dir = bgcflow_dir / f\"config/{project_name}\"\n    project_dir.mkdir(parents=True, exist_ok=True)\n\n    # Handle samples_csv input\n    if isinstance(samples_csv, pd.core.frame.DataFrame):\n        logging.debug(\"Generating samples file from Pandas DataFrame\")\n        assert samples_csv.index.name == \"genome_id\"\n        assert (\n            samples_csv.columns\n            == [\n                \"source\",\n                \"organism\",\n                \"genus\",\n                \"species\",\n                \"strain\",\n                \"closest_placement_reference\",\n            ]\n        ).all\n        samples_csv.to_csv(project_dir / \"samples.csv\")\n    elif isinstance(samples_csv, str):\n        logging.debug(f\"Copying samples file from {samples_csv}\")\n        samples_csv = Path(samples_csv)\n        assert samples_csv.is_file()\n        shutil.copy(samples_csv, project_dir / \"samples.csv\")\n\n    # Handle prokka_db input\n    if isinstance(prokka_db, str):\n        logging.debug(f\"Copying custom annotation file from {prokka_db}\")\n        prokka_db = Path(prokka_db)\n        assert prokka_db.is_file()\n        shutil.copy(prokka_db, project_dir / \"prokka-db.csv\")\n        template_dict[\"prokka-db\"] = \"prokka-db.csv\"\n\n    # Handle gtdb_tax input\n    if isinstance(gtdb_tax, str):\n        logging.debug(f\"Copying custom taxonomy from {gtdb_tax}\")\n        gtdb_tax = Path(gtdb_tax)\n        assert gtdb_tax.is_file()\n        shutil.copy(gtdb_tax, project_dir / \"gtdbtk.bac120.summary.tsv\")\n        template_dict[\"gtdb-tax\"] = \"gtdbtk.bac120.summary.tsv\"\n\n    # Update template_dict with project description\n    if isinstance(description, str):\n        logging.debug(\"Writing project description...\")\n        template_dict[\"description\"] = description\n\n    # Generate project configuration file\n    logging.info(f\"Project config file generated in: {project_dir}\")\n    with open(project_dir / \"project_config.yaml\", \"w\") as file:\n        yaml.dump(template_dict, file, sort_keys=False)\n\n    # Initialize global config if not present\n    if not global_config.is_file():\n        bgcflow_init(bgcflow_dir, global_config)\n\n    # Update global config.yaml with project information\n    with open(bgcflow_dir / \"config/config.yaml\", \"r\") as file:\n        logging.debug(\"Updating global config.yaml\")\n        main_config = yaml.safe_load(file)\n\n        # Rename 'pep' to 'name' for consistency\n        for item in main_config[\"projects\"]:\n            if \"pep\" in item:\n                item[\"name\"] = item.pop(\"pep\")\n\n        # Rename 'pipelines' to 'rules'\n        if \"pipelines\" in main_config.keys():\n            main_config[\"rules\"] = main_config.pop(\"pipelines\")\n\n        project_names = [p[\"name\"] for p in main_config[\"projects\"]]\n        assert (\n            project_name not in project_names\n        ), f\"Project name: '{project_name}' already exists!\\nUse a different name or edit the files in: {project_dir}\"\n        assert (\n            str(project_dir / \"project_config.yaml\") not in project_names\n        ), f\"Project name: '{project_name}' already exists!\\nUse a different name or edit the files in: {project_dir}\"\n        main_config[\"projects\"].append(\n            {\"name\": str(project_dir / \"project_config.yaml\")}\n        )\n\n    # Update and save global config\n    with open(bgcflow_dir / \"config/config.yaml\", \"w\") as file:\n        yaml.dump(main_config, file, sort_keys=False)\n</code></pre>"},{"location":"api/#bgcflow.projects_util.projects_util","title":"<code>projects_util(**kwargs)</code>","text":"<p>Utility function for managing BGCflow projects.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Keyword arguments for the function.</p> <code>{}</code> <p>Keyword arguments:</p> Name Type Description <code>bgcflow_dir</code> <code>str</code> <p>Path to the BGCflow directory.</p> <code>project</code> <code>str</code> <p>Name of the BGCflow project to generate.</p> <code>use_project_pipeline</code> <code>bool</code> <p>Whether to use the project-specific pipeline rules.</p> <code>prokka_db</code> <code>str</code> <p>Path to the Prokka database.</p> <code>gtdb_tax</code> <code>str</code> <p>Path to the GTDB taxonomy file.</p> <code>samples_csv</code> <code>str</code> <p>Path to the samples CSV file.</p> Source code in <code>bgcflow/projects_util.py</code> <pre><code>def projects_util(**kwargs):\n    \"\"\"\n    Utility function for managing BGCflow projects.\n\n    Args:\n        **kwargs (dict): Keyword arguments for the function.\n\n    Keyword Arguments:\n        bgcflow_dir (str): Path to the BGCflow directory.\n        project (str): Name of the BGCflow project to generate.\n        use_project_pipeline (bool): Whether to use the project-specific pipeline rules.\n        prokka_db (str): Path to the Prokka database.\n        gtdb_tax (str): Path to the GTDB taxonomy file.\n        samples_csv (str): Path to the samples CSV file.\n    \"\"\"\n\n    # pep_version = \"2.1.0\"\n    bgcflow_dir = Path(kwargs[\"bgcflow_dir\"]).resolve()\n    config_dir = bgcflow_dir / \"config\"\n    config_dir.mkdir(parents=True, exist_ok=True)\n    global_config = config_dir / \"config.yaml\"\n\n    if type(kwargs[\"project\"]) == str:\n        # project_name = kwargs[\"project\"]\n\n        generate_project(\n            bgcflow_dir,\n            kwargs[\"project\"],\n            use_project_rules=kwargs[\"use_project_pipeline\"],\n            prokka_db=kwargs[\"prokka_db\"],\n            gtdb_tax=kwargs[\"gtdb_tax\"],\n            samples_csv=kwargs[\"samples_csv\"],\n        )\n    else:\n        bgcflow_init(bgcflow_dir, global_config)\n</code></pre>"},{"location":"authors/","title":"Authors","text":""},{"location":"authors/#credits","title":"Credits","text":""},{"location":"authors/#development-lead","title":"Development Lead","text":"<ul> <li>Matin Nuhamunada matinnu@biosustain.dtu.dk</li> <li>Omkar S. Mohite omkmoh@biosustain.dtu.dk</li> </ul>"},{"location":"authors/#contributors","title":"Contributors","text":"<p>None yet. Why not be the first?</p>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/NBChub/bgcflow_wrapper/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p><code>bgcflow_wrapper</code> could always use more documentation, whether as part of the official <code>bgcflow_wrapper</code> docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/NBChub/bgcflow_wrapper/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions   are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up <code>bgcflow_wrapper</code> for local development.</p> <ol> <li>Fork the <code>bgcflow_wrapper</code> repo on GitHub.</li> <li>Clone your fork locally</li> </ol> <pre><code>    $ git clone git@github.com:your_name_here/bgcflow_wrapper.git\n</code></pre> <ol> <li>Ensure poetry is installed.</li> <li>Install dependencies and start your virtualenv:</li> </ol> <pre><code>    $ poetry install -E test -E doc -E dev\n</code></pre> <ol> <li>Create a branch for local development:</li> </ol> <pre><code>    $ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> <ol> <li>When you're done making changes, check that your changes pass the    tests, including testing other Python versions, with tox:</li> </ol> <pre><code>    $ tox\n</code></pre> <ol> <li>Commit your changes and push your branch to GitHub:</li> </ol> <pre><code>    $ git add .\n    $ git commit -m \"Your detailed description of your changes.\"\n    $ git push origin name-of-your-bugfix-or-feature\n</code></pre> <ol> <li>Submit a pull request through the GitHub website.</li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated. Put    your new functionality into a function with a docstring, and add the    feature to the list in README.md.</li> <li>The pull request should work for Python <code>3.8</code>, <code>3.9</code>, <code>3.10</code> and for PyPy. Check    https://github.com/NBChub/bgcflow_wrapper/actions    and make sure that the tests pass for all supported Python versions.</li> </ol>"},{"location":"contributing/#tips","title":"Tips","text":"<p><pre><code>    $ pytest tests.test_bgcflow_wrapper\n</code></pre> To run a subset of tests.</p>"},{"location":"contributing/#deploying","title":"Deploying","text":"<p>A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in HISTORY.md). Then run:</p> <pre><code>$ poetry patch # possible: major / minor / patch\n$ git push\n$ git push --tags\n</code></pre> <p>Github Actions will then deploy to PyPI if tests pass.</p>"},{"location":"history/","title":"History","text":""},{"location":"history/#history","title":"History","text":""},{"location":"history/#040-2024-12-05","title":"0.4.0 (2024-12-05)","text":"<ul> <li>Upgrade Snakemake to v8.25.5</li> <li>Feat: Add <code>bgcflow run --antismash_mode</code> to enable use <code>fungi</code> version using BGCFlow environment variables</li> <li>Fix: Security updates</li> <li>Full Changelog</li> </ul>"},{"location":"history/#040-2024-06-20","title":"0.4.0 (2024-06-20)","text":"<ul> <li>Upgrade Snakemake to v8.14.0</li> <li>Fix: Improve <code>get-result</code> command to be more intuitive</li> <li>Docs: Update citation</li> <li>Full Changelog</li> </ul>"},{"location":"history/#035-2024-06-01","title":"0.3.5 (2024-06-01)","text":"<ul> <li>Snakemake fix and security update by @matinnuhamunada in https://github.com/NBChub/bgcflow_wrapper/pull/39</li> <li>Fix: Pin pulp version to 2.7.0 to address snakemake dependency issue: https://github.com/snakemake/snakemake/issues/2606</li> <li>Feat: add <code>--profile</code> parameters on <code>bgcflow</code> run to use snakemake profiles</li> <li>Chore(deps): bump pip from 22.3.1 to 23.3 by @dependabot in https://github.com/NBChub/bgcflow_wrapper/pull/40</li> <li>Full Changelog</li> </ul>"},{"location":"history/#034-2023-11-22","title":"0.3.4 (2023-11-22)","text":"<ul> <li>Synchronize with BGCFlow version 0.7.9</li> <li>Feat: add CLI option for lsabgc and ppanggolin by @matinnuhamunada in PR #37</li> <li>Chore: Auto detect available CPU</li> <li>Feat: give option to turn off panoptes</li> <li>Full Changelog</li> </ul>"},{"location":"history/#033-2023-11-20","title":"0.3.3 (2023-11-20)","text":"<ul> <li>Fix: Pin snakemake to v7.31.1 for compatibility with panoptes-ui job monitoring. PR #35</li> <li>Chore: Security updates. PR #35</li> <li>Full Changelog</li> </ul>"},{"location":"history/#032-2023-10-12","title":"0.3.2 (2023-10-12)","text":"<ul> <li>Release package in PyPi</li> <li>Change: Downgrade pandas. PR #29</li> <li>Chore: Dependency updates including urllib3 and cryptography. PR #31, PR #30</li> <li>New Contributor: @dependabot. PR #31</li> <li>Full Changelog</li> </ul>"},{"location":"history/#031-2023-08-27","title":"0.3.1 (2023-08-27)","text":"<ul> <li>Update: Read project metadata for dbt models synchronization. Manual definition of dbt models to exclude also added.</li> <li>Full Changelog</li> </ul>"},{"location":"history/#030-2023-08-26","title":"0.3.0 (2023-08-26)","text":"<ul> <li>Docs: Refer to wiki for tutorial. PR #26</li> <li>Feature: Use metabase API and dbt-metabase for uploading and syncing model relationships. PR #27</li> <li>Full Changelog</li> </ul>"},{"location":"history/#028-2023-08-21","title":"0.2.8 (2023-08-21)","text":"<ul> <li>Improvement: Enhanced <code>mkdocs</code> report handling, dependency management, and example copying in <code>bgcflow init</code>.</li> <li>Update: Utilize BGCFlow v0.7.2 version dependencies metadata.</li> <li>Full Changelog</li> </ul>"},{"location":"history/#027-2023-08-09","title":"0.2.7 (2023-08-09)","text":"<ul> <li>New Feature: Organize report by subcategory.</li> <li>Full Changelog</li> </ul>"},{"location":"history/#026-2023-08-09","title":"0.2.6 (2023-08-09)","text":"<ul> <li>Security Update: Addressed security concerns.</li> <li>Improvements: CLI, testing, and new features including panoptes wrapper and subworkflows.</li> <li>Full Changelog</li> </ul>"},{"location":"history/#025-2023-08-01","title":"0.2.5 (2023-08-01)","text":"<ul> <li>Fix: Correct alias parsing to accommodate bgcflow v0.7.0. PR #20</li> <li>Chore: Security update. PR #21</li> <li>New Contributor: @OmkarSaMo. PR #19</li> <li>Full Changelog</li> </ul>"},{"location":"history/#024-2023-06-27","title":"0.2.4 (2023-06-27)","text":"<ul> <li>Update: Dependency update for improved stability and performance. PR #17, PR #18</li> <li>Full Changelog</li> </ul>"},{"location":"history/#023-2023-06-15","title":"0.2.3 (2023-06-15)","text":"<ul> <li>Fix: Correct UnicodeEncodeError in Windows. PR #7</li> <li>Docs: Add graphical abstract. PR #16</li> <li>This release is compatible with BGCFlow version 0.6.1 and version 0.6.2.</li> <li>Full Changelog</li> </ul>"},{"location":"history/#022-2023-01-30","title":"0.2.2 (2023-01-30)","text":"<ul> <li>Pre-release: Compatibility with BGCFlow 0.6.0.</li> <li>Full Changelog</li> </ul>"},{"location":"history/#021-2022-11-18","title":"0.2.1 (2022-11-18)","text":"<ul> <li>Migration: Migrate to NBChub repo.</li> <li>Full Changelog</li> </ul>"},{"location":"history/#020-2022-11-18","title":"0.2.0 (2022-11-18)","text":"<ul> <li>Minor updates and enhancements.</li> <li>Full Changelog</li> </ul>"},{"location":"history/#010-2022-11-17","title":"0.1.0 (2022-11-17)","text":"<ul> <li>Initial release of the package.</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install bgcflow_wrapper, run this command in your terminal:</p> <pre><code>pip install bgcflow_wrapper\n</code></pre> <p>This is the preferred method to install bgcflow_wrapper, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-source","title":"From source","text":"<p>The source for bgcflow_wrapper can be downloaded from the Github repo.</p> <p>You can either clone the public repository:</p> <pre><code>git clone git://github.com/NBChub/bgcflow_wrapper\n</code></pre> <p>Or download the tarball:</p> <pre><code>curl -OJL https://github.com/NBChub/bgcflow_wrapper/tarball/master\n</code></pre> <p>Once you have a copy of the source, you can install it with:</p> <pre><code>pip install .\n</code></pre>"},{"location":"tutorial/","title":"Tutorial","text":"<p>Please refer to the <code>BGCFlow</code> WIKI for detailed examples and use cases:</p> <p></p> <p>We are still working on the tutorial of using <code>BGCFlow</code> and the <code>bgcflow_wrapper</code>. The work in progress tutorial can be found at NBCHub.</p>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#using-as-a-command-line-interface","title":"Using as a command line interface","text":"<p>This is the main intention of BGCFlow wrapper usage.</p>"},{"location":"usage/#overview","title":"Overview","text":"<pre><code>$ bgcflow\n\nUsage: bgcflow [OPTIONS] COMMAND [ARGS]...\n\n  A snakemake wrapper and utility tools for BGCFlow\n  (https://github.com/NBChub/bgcflow)\n\nOptions:\n  --version   Show the version and exit.\n  -h, --help  Show this message and exit.\n\nCommands:\n  build       Build Markdown report or use dbt to build DuckDB database.\n  clone       Get a clone of BGCFlow to local directory.\n  deploy      [EXPERIMENTAL] Deploy BGCFlow locally using snakedeploy.\n  get-result  View a tree of a project results or get a copy using Rsync.\n  init        Create projects or initiate BGCFlow config from template.\n  pipelines   Get description of available pipelines from BGCFlow.\n  run         A snakemake CLI wrapper to run BGCFlow.\n  serve       Serve static HTML report or other utilities (Metabase, etc.).\n  sync        Uploads and sync DuckDB database to Metabase.\n</code></pre>"},{"location":"usage/#typical-usage","title":"Typical Usage","text":"<ul> <li> <p>The first step of using BGCFlow wrapper is to get a copy (or clone) of the main BGCFlow Snakemake workflow. <pre><code># get a clone of BGCFlow in your local machine\nbgcflow clone MY_BGCFLOW_PATH #change PATH accordingly\ncd MY_BGCFLOW_PATH\n</code></pre></p> </li> <li> <p>Then, initiate a project config by: <pre><code># initiate an example config and projects from template\nbgcflow init\n</code></pre></p> <p>This will generate a file called <code>config.yaml</code> in the <code>config/</code> folder inside the cloned BGCFlow directory with an example project</p> </li> <li> <p>Once the config files are set, we can do a snakemake dry-run: <pre><code># do a dry-run\nbgcflow run -n\n</code></pre></p> <ul> <li>While the workflow is running, the command automatically serve <code>Panoptes-UI</code> at <code>localhost:5000</code>` to monitor jobs.</li> <li>If there is an instance of Panoptes already running in the designated port, the the run will use that instance instead. You can start panoptes manually by running <code>bgcflow serve --panoptes</code></li> </ul> </li> <li> <p>When all setting are correct, we can run the workflow: <pre><code>bgcflow run\n</code></pre></p> </li> <li> <p>Once the job is completed, we can build a static HTML report: <pre><code># build a static HTML report\nbgcflow build report\n</code></pre></p> </li> <li> <p>To serve the static HTML report, do: <pre><code>bgcflow serve --project &lt;project name&gt;\n</code></pre></p> </li> <li> <p>We can also build a DuckDB database from the results: <pre><code>bgcfow build database\n</code></pre></p> </li> <li> <p>The database can be uploaded to Metabase for visualization. To start a Metabase instance, do: <pre><code>bgcflow serve --metabase\n</code></pre></p> </li> <li> <p>To upload and sync the database to Metabase, do: <pre><code>bgcflow sync &lt;project name&gt;\n</code></pre></p> </li> <li> <p>To find out all the rules that can be added in the configuration file, do: <pre><code># find out available rules\nbgcflow pipelines --bgcflow_dir MY_BGCFLOW_PATH\n</code></pre></p> </li> <li> <p>To get more details about each individual rules, do: <pre><code># get description of a rule\nbgcflow pipelines --describe antismash --bgcflow_dir MY_BGCFLOW_PATH/\n</code></pre></p> </li> <li> <p>To find out how to cite each rules, do: <pre><code># get citation of a rule\nbgcflow pipelines --cite antismash --bgcflow_dir MY_BGCFLOW_PATH/\n</code></pre></p> </li> </ul>"},{"location":"usage/#using-as-a-python-library","title":"Using as a python library","text":"<p>You can also generate new projects via python or Jupyter notebooks: <pre><code>from bgcflow.projects_util import generate_project\nimport pandas as pd\n\ndf_samples = pd.read_csv('samples.csv', index_col=0)\ndescription = \"Project generated from notebook\"\n\ngenerate_project(\"BGCFLOW_PATH\",\n                \"MY_PROJECT\",\n                use_project_rules=True,\n                samples_csv=df_samples,\n                prokka_db=\"prokka-db.csv\",\n                gtdb_tax=\"gtdbtk.bac120.summary.tsv\",\n                description=description\n                )\n</code></pre></p>"}]}